version: '3.8'

services:
  # Backend API service with hot-reload and debugging
  api:
    build:
      context: ../../src/backend
      dockerfile: ../../infrastructure/docker/api.Dockerfile
      target: development
      args:
        NODE_ENV: development
    volumes:
      - ../../src/backend:/app
      - node_modules:/app/node_modules
    ports:
      - "3000:3000"
      - "9229:9229" # Debug port
    environment:
      - NODE_ENV=development
      - PORT=3000
      - DEBUG=smart-apparel:*
      - MONGO_URI=mongodb://mongodb:27017/smartapparel
      - REDIS_URI=redis://redis:6379
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=smart-apparel-api-dev
      - KAFKA_GROUP_ID=api-consumers-dev
      - INFLUXDB_URL=http://influxdb:8086
      - ELASTIC_NODE=http://elasticsearch:9200
    depends_on:
      - mongodb
      - redis
      - kafka
      - influxdb
      - elasticsearch
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # Frontend web application with Vite hot-reload
  web:
    build:
      context: ../../src/web
      dockerfile: ../../infrastructure/docker/web.Dockerfile
      target: development
      args:
        NODE_ENV: development
    volumes:
      - ../../src/web:/app
      - web_node_modules:/app/node_modules
    ports:
      - "5173:5173"
    environment:
      - NODE_ENV=development
      - VITE_API_URL=http://localhost:3000
      - VITE_WS_URL=ws://localhost:3000
      - VITE_DEBUG=true
    depends_on:
      - api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5173"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Background workers for data processing
  worker:
    build:
      context: ../../src/backend
      dockerfile: ../../infrastructure/docker/worker.Dockerfile
      target: development
      args:
        NODE_ENV: development
    volumes:
      - ../../src/backend:/app
      - worker_node_modules:/app/node_modules
    environment:
      - NODE_ENV=development
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=smart-apparel-worker-dev
      - KAFKA_GROUP_ID=worker-consumers-dev
      - REDIS_URI=redis://redis:6379
      - MONGO_URI=mongodb://mongodb:27017/smartapparel
      - DEBUG=smart-apparel:worker:*
    depends_on:
      - kafka
      - redis
      - mongodb

  # MongoDB database
  mongodb:
    image: mongo:6.0
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    command: ["mongod", "--wiredTigerCacheSizeGB", "1"]
    environment:
      - MONGO_INITDB_DATABASE=smartapparel
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and session storage
  redis:
    image: redis:7.0-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --save 60 1 --loglevel warning
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kafka for event streaming
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    healthcheck:
      test: ["CMD", "zkServer.sh", "status"]
      interval: 30s
      timeout: 10s
      retries: 3

  # InfluxDB for time series data
  influxdb:
    image: influxdb:2.7-alpine
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb2
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=adminpassword
      - DOCKER_INFLUXDB_INIT_ORG=smartapparel
      - DOCKER_INFLUXDB_INIT_BUCKET=sensor_data

  # Elasticsearch for search and analytics
  elasticsearch:
    image: elasticsearch:8.9.0
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m

volumes:
  mongodb_data:
  redis_data:
  influxdb_data:
  elasticsearch_data:
  node_modules:
  web_node_modules:
  worker_node_modules:

networks:
  default:
    name: smartapparel_dev
    driver: bridge